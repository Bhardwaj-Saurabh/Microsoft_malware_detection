# Microsoft Malware Detection: Data Science Project 
<img src="images/malware.jpg" alt="Malware">

## 1. Problem Statement
The malware industry continues to be a well-organized, well-funded market dedicated to evading traditional security measures. Once a computer is infected by malware, criminals can hurt consumers and enterprises in many ways.

With more than one billion enterprise and consumer customers, Microsoft takes this problem very seriously and is deeply invested in improving security.

As one part of their overall strategy for doing so, Microsoft is challenging the data science community to develop techniques to predict if a machine will soon be hit with malware. Microsoft is providing Kagglers with an unprecedented malware dataset to encourage open-source progress on effective techniques for predicting malware occurrences.

## 2. Goal
The goal of this project is to predict a Windows machine’s probability of getting infected by various families of malware, based on different properties of that machine. 

## 3. Requirements & Constraints
### 3.1 Functional Requirements
The web application should provide the following functionality:
- Users can provide the process parameters to the model and receive a prediction of whether the equipment will get infected or not.
- Users can view and infer the performance metrics of different machine learning models.
Users can visualize the data and gain insights into the behavior of the equipment.

### 3.2 Non-functional Requirements
The web application should meet the following non-functional requirements:

- The model should have high precision, recall, and F1 score.
- The web application should be responsive and easy to use.
- The web application should be secure and protect user data.

### 3.3 Constraints
The application should be built using Flask and deployed using Docker.
- The cost of deployment should be minimal.

### 3.4 Out-of-scope
- Integrating with external applications or data sources.
- Providing detailed equipment diagnostic information.

## 4. Data Description
The dataset used in this project is provided by Microsidft. Although, it contains almost 8 millions records based on 83 different features, due to system capacity, I have used 100000 records to complete this project. Some of the import features in the dataset are based on App version, Windows Version, Anti-virus Version, Operating System, Storage, Display used, and RAM used in the machines. The dataset is publicly available at [Kaggle](https://www.kaggle.com/). 

The dataset has two different classes in target column and is balanced, and contains missing or null values. It is considered a chellenging project in machine learning and data science community for tasks such as classification, clustering, and feature selection. 

Some of the important properties from the dataset is shown below.

<img src="images/des1.png" alt="Malware" width="400" height="300"> <img src="images/des2.png" alt="Malware" width="400" height="300"> <img src="images/des3.png" alt="Malware" width="400" height="300"> 
<img src="images/osplat.png" alt="Malware" width="400" height="300"> 
<img src="images/ram.png" alt="Malware" width="400" height="300">  <img src="images/category.png" alt="Malware" width="400" height="300"> 
<img src="images/diagonalinternal.png" alt="Malware" width="400" height="300"> <img src="images/nontouch.png" alt="Malware" width="400" height="300"> <img src="images/processcore.png" alt="Malware" width="400" height="300"> <img src="images/target.png" alt="Malware" width="400" height="300"> 

## 5. Data Preprocessing:
For this project, the data was prepared by removing features with zero standard deviation and more than 90% missing values and splitting the dataset into training and testing sets using a 75/25 split ratio. To improve the model performance, some features based on App version, Windows Version, Anti-virus Version, Operating System, Storage, Display used, and RAM were also engineered and added to the dataset. Below steps are taken to preprocess the data before training. 

1. Identify columns with more than 60% missing values, 70% cardiniality, and 100% standard deviation. 
2. Engineered categirical features based on some of the columns such as `OsBuildLab`, `OsBuildLab`, `Census_OSVersion` and numerical features based such as `primary_drive_c_ratio`, `aspect_ratio`, `Screen_Area` etc.
3. Drop rows with the missing values.
4. Used Frequency encoding for features with more than 30 unique values and ordinal encoding for rest of the categorical features. 
5. Used minmax scalling for all the numerical features in the dataset. 

For the detail data description and data preprocessing, please check the [data decription](notebook/Malware Detection.ipynb) file.

## 6. Performance Metrics
The success of the project will be measured based on the following metrics:

- Precsion, recall, and F1 score of the machine learning models.
- As the aim is to detect the malware, precision and f1-score is a good metric to focus.
- Responsiveness and ease of use of the web application.
- Identify windows system which are vunrable to malware attacks.

## 7. Methodology
<img src="images/arc.png" alt="Malware"> 

The MLOps (Machine Learning Operations) pipeline project is designed to create an end-to-end workflow for developing and deploying a web application that performs data preprocessing, model training, model evaluation, and prediction. The pipeline leverages Docker containers for encapsulating code, artifacts, and both the frontend and backend components of the application. The application is deployed only locally but can be easilyt deployed with the help of a cloud hosting solution.

The pipeline follows the following sequence of steps:

1. **Data Ingestion** - Ingest the data into the feature store and divide the data into train and test dataset.
2. **Data Validation** - Check data drift and validate the data. 
3. **Data Preprocessing** - Treat missing values, high cardiniality, feature engineering, feature encoding and feature scalling.
4. **Model Building** - Build a baseline model and compare several models to compare the model performance. Select final model based on performance metric. Final model is selected based on the accuracy, model training time. Perform hyper-parameter tuning to search for highest accuracy. 
5. **Model Evaluation** - Checked accuracy, precision and recall score, F1-score and AUC and ROC score. Plot AUC. Check for model capture rate for model diagnosis and select final model.
6. **Model Pusher** - Compare previously trained model and currently trained model to push the better model into the pipeline. 
7. **Flash Application** based web appilication to make batch inferences. 
8. **CI/CD Pipeline** - The pipeline is automated using GitHub Actions, which allows for continuous integration and deployment of the application. This automation ensures that the application is always up-to-date and provides a consistent experience for users.

## 8. Results
Following models with StratifiedKFold cross-validation have been trained.

|model|accuracy|
|--|--|
|LogisticRegression|0.637|
|DecisionTreeClassifier|0.569|
|RandomForestClassifier|0.639|
|GaussianNB|0.600|
|SVC|0.638|
|XGBClassifier|0.632|
|LGBMClassifier|0.647|


### 8.1 Model Comparision
<img src="images/compare.png" alt="Malware" width="600" height="400"> 

### 8.2 Final Metrics
|model|accuracy|f1-score|Concordance|auc|
|--|--|--|--|--|
|LGBMClassifier|0.647|0.64|0.699|0.699|

<img src="images/roc.png" alt="Malware" width="400" height="300"> <img src="images/pr.png" alt="Malware" width="400" height="300"> <img src="images/capture.png" alt="Malware" width="400" height="300"> <img src="images/infect.png" alt="Malware" width="400" height="300"> 

### 8.3 Feature Selection
The most important features idenfitied by the final model are shown in the plot below.

<img src="images/feature.png" alt="Malware">

## 9. Dependencies and Requirements
### 9.1 Create a conda enviornment
```
conda create -n env python=3.8
``` 
### 9.2 Activate the enviornment
```
conda activate env
```
### 9.3 Install the necessary dependencies
```
pip install -r requirements.txt
``` 

## 10. Usage Instructions
To run locally, please following steps
### 10.1 Clone the github repo
```
git clone https://github.com/Bhardwaj-Saurabh/Microsoft_malware_detection.git
``` 

### 10.2 Change current directory
```
cd Microsoft_malware_detection
``` 

### 10.3 Run the training pipeline
```
python main.py
``` 

### 10.4 Run the web app
```
python app.py
``` 
<img src="images/app.png" alt="Malware"> 


## 11. Conclusion

In this project, the goal is to predict a Windows machine’s probability of getting infected by various families of malware, based on different properties of that machine and to deploy a prediction web application to get the final prediction. To achieve this goal, A detail EDA to under data and it's properties was completed. Using the result of EDA, data preprocessing and model experiements were performed. Final, based on the selected meterics, a final model was selected. 

To deploy the Flask web application, a pipeline of different ML components is built and successfully deployed.

The greatest challenge in this project was to deal with cardiniality of caterogirical features. Even though the dataset is quite large, due to high cardiniality the train and test split of the data has data leakage. To deal with this challange, different encoding method for test data set has been adopted. Due to this different ecoding method for test data, there is a big gap between training and testing accuracy. 

In order to improve the testing accuracy score, following steps can be taken.

- Find a better way to impute the missing value especially for categorical features.
- Find features which directly affects the model performance and train model with only those.
- Split the train and test set so there are no unique values in test set to handle data leakage. 
- Try to train the model with more data with Neural network.

Overall, it is a challenging project and working on this project definitely has given me the confidence and skills to complete an end to end data science project. 

## 12. Licence, Author, & Acknowldgement

[MIT Licence](LICENSE)

**Acknowledgements**

This competition is hosted by Microsoft, Windows Defender ATP Research, Northeastern University College of Computer and Information Science, and Georgia Tech Institute for Information Security & Privacy.

**Data Souce:**

The dataset is publicly available at [Kaggle](https://kaggle.com/competitions/microsoft-malware-prediction). 
Addison Howard, Ben Hope, Brendan Saltaformaggio, Eric Avena, Mansour Ahmadi, Matthew Duncan, n_30, Rob McCann, Will Cukierski. (2018). Microsoft Malware Prediction. Kaggle. 

**Author:** Saurabh Bhardwaj

**Contact:** [LinkedIn](https://www.linkedin.com/in/saurabhbhardwajofficial)